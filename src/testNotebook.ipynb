{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44000167-076c-458b-a015-5cc7d8f1989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from tqdm import tqdm\n",
    "\n",
    "from classifier import Classifier\n",
    "from dataset.dataset import get_val_loader\n",
    "from model.pspnet import get_model\n",
    "from util import get_model_dir, fast_intersection_and_union, setup_seed, resume_random_state, find_free_port, setup, \\\n",
    "    cleanup, get_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e8e8d-cbbc-4457-a44d-7415de077372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Testing')\n",
    "    return get_cfg(parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b9c9c-a5cb-4939-a82e-7adfd98471fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(rank: int, world_size: int, args: argparse.Namespace) -> None:\n",
    "    print(f\"==> Running evaluation script\")\n",
    "    setup(args, rank, world_size)\n",
    "    setup_seed(args.manual_seed)\n",
    "\n",
    "    # ========== Data  ==========\n",
    "    val_loader = get_val_loader(args)\n",
    "\n",
    "    # ========== Model  ==========\n",
    "    model = get_model(args).to(rank)\n",
    "    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    root = get_model_dir(args)\n",
    "\n",
    "    print(\"=> Creating the model\")\n",
    "    if args.ckpt_used is not None:\n",
    "        filepath = os.path.join(root, f'{args.ckpt_used}.pth')\n",
    "        assert os.path.isfile(filepath), filepath\n",
    "        checkpoint = torch.load(filepath)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> Loaded weight '{}'\".format(filepath))\n",
    "    else:\n",
    "        print(\"=> Not loading anything\")\n",
    "\n",
    "    # ========== Test  ==========\n",
    "    validate(args=args, val_loader=val_loader, model=model)\n",
    "    cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cf292-6d92-4ef7-87fc-76b92007b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(args: argparse.Namespace, val_loader: torch.utils.data.DataLoader, model: DDP) -> Tuple[torch.tensor, torch.tensor]:\n",
    "    print('\\n==> Start testing ({} runs)'.format(args.n_runs), flush=True)\n",
    "    random_state = setup_seed(args.manual_seed, return_old_state=True)\n",
    "    device = torch.device('cuda:{}'.format(dist.get_rank()))\n",
    "    model.eval()\n",
    "\n",
    "    c = model.module.bottleneck_dim\n",
    "    h = model.module.feature_res[0]\n",
    "    w = model.module.feature_res[1]\n",
    "\n",
    "    nb_episodes = len(val_loader) if args.test_num == -1 else int(args.test_num / args.batch_size_val)\n",
    "    runtimes = torch.zeros(args.n_runs)\n",
    "    base_mIoU, novel_mIoU = [torch.zeros(args.n_runs, device=device) for _ in range(2)]\n",
    "\n",
    "    # ========== Perform the runs  ==========\n",
    "    for run in range(args.n_runs):\n",
    "        print('Run', run + 1, 'of', args.n_runs)\n",
    "        # The order of classes in the following tensors is the same as the order of classifier (novels at last)\n",
    "        cls_intersection = torch.zeros(args.num_classes_tr + args.num_classes_val)\n",
    "        cls_union = torch.zeros(args.num_classes_tr + args.num_classes_val)\n",
    "        cls_target = torch.zeros(args.num_classes_tr + args.num_classes_val)\n",
    "\n",
    "        runtime = 0\n",
    "        features_s, gt_s = None, None\n",
    "        if not args.generate_new_support_set_for_each_task:\n",
    "            with torch.no_grad():\n",
    "                spprt_imgs, s_label = val_loader.dataset.generate_support([], remove_them_from_query_data_list=True)\n",
    "                nb_episodes = len(val_loader) if args.test_num == -1 else nb_episodes  # Updates nb_episodes since some images were removed by generate_support\n",
    "                spprt_imgs = spprt_imgs.to(device, non_blocking=True)\n",
    "                s_label = s_label.to(device, non_blocking=True)\n",
    "                features_s = model.module.extract_features(spprt_imgs).detach().view((args.num_classes_val, args.shot, c, h, w))\n",
    "                gt_s = s_label.view((args.num_classes_val, args.shot, args.image_size, args.image_size))\n",
    "\n",
    "        for _ in tqdm(range(nb_episodes), leave=True):\n",
    "            t0 = time.time()\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    loader_output = next(iter_loader)\n",
    "                except (UnboundLocalError, StopIteration):\n",
    "                    iter_loader = iter(val_loader)\n",
    "                    loader_output = next(iter_loader)\n",
    "                qry_img, q_label, q_valid_pix, img_path = loader_output\n",
    "\n",
    "                qry_img = qry_img.to(device, non_blocking=True)\n",
    "                q_label = q_label.to(device, non_blocking=True)\n",
    "                features_q = model.module.extract_features(qry_img).detach().unsqueeze(1)\n",
    "                valid_pixels_q = q_valid_pix.unsqueeze(1).to(device)\n",
    "                gt_q = q_label.unsqueeze(1)\n",
    "\n",
    "                query_image_path_list = list(img_path)\n",
    "                if args.generate_new_support_set_for_each_task:\n",
    "                    spprt_imgs, s_label = val_loader.dataset.generate_support(query_image_path_list)\n",
    "                    spprt_imgs = spprt_imgs.to(device, non_blocking=True)\n",
    "                    s_label = s_label.to(device, non_blocking=True)\n",
    "                    features_s = model.module.extract_features(spprt_imgs).detach().view((args.num_classes_val, args.shot, c, h, w))\n",
    "                    gt_s = s_label.view((args.num_classes_val, args.shot, args.image_size, args.image_size))\n",
    "\n",
    "            # =========== Initialize the classifier and run the method ===============\n",
    "            base_weight = model.module.classifier.weight.detach().clone().T\n",
    "            base_bias = model.module.classifier.bias.detach().clone()\n",
    "            classifier = Classifier(args, base_weight, base_bias, n_tasks=features_q.size(0))\n",
    "            classifier.init_prototypes(features_s, gt_s)\n",
    "            classifier.compute_pi(features_q, valid_pixels_q, gt_q)  # gt_q won't be used in optimization if pi estimation strategy is self or uniform\n",
    "            classifier.optimize(features_s, features_q, gt_s, valid_pixels_q)\n",
    "\n",
    "            runtime += time.time() - t0\n",
    "\n",
    "            # =========== Perform inference and compute metrics ===============\n",
    "            logits = classifier.get_logits(features_q).detach()\n",
    "            probas = classifier.get_probas(logits)\n",
    "\n",
    "            intersection, union, target = fast_intersection_and_union(probas, gt_q)  # [batch_size_val, 1, num_classes]\n",
    "            intersection, union, target = intersection.squeeze(1).cpu(), union.squeeze(1).cpu(), target.squeeze(1).cpu()\n",
    "            cls_intersection += intersection.sum(0)\n",
    "            cls_union += union.sum(0)\n",
    "            cls_target += target.sum(0)\n",
    "\n",
    "        base_count, novel_count, sum_base_IoU, sum_novel_IoU = 4 * [0]\n",
    "        for i, class_ in enumerate(val_loader.dataset.all_classes):\n",
    "            if cls_union[i] == 0:\n",
    "                continue\n",
    "            IoU = cls_intersection[i] / (cls_union[i] + 1e-10)\n",
    "            print(\"Class {}: \\t{:.4f}\".format(class_, IoU))\n",
    "            if class_ in val_loader.dataset.base_class_list:\n",
    "                sum_base_IoU += IoU\n",
    "                base_count += 1\n",
    "            elif class_ in val_loader.dataset.novel_class_list:\n",
    "                sum_novel_IoU += IoU\n",
    "                novel_count += 1\n",
    "\n",
    "        avg_base_IoU, avg_novel_IoU = sum_base_IoU / base_count, sum_novel_IoU / novel_count\n",
    "        print('Mean base IoU: {:.4f}, Mean novel IoU: {:.4f}'.format(avg_base_IoU, avg_novel_IoU), flush=True)\n",
    "\n",
    "        base_mIoU[run], novel_mIoU[run] = avg_base_IoU, avg_novel_IoU\n",
    "        runtimes[run] = runtime\n",
    "\n",
    "    agg_mIoU = (base_mIoU.mean() + novel_mIoU.mean()) / 2\n",
    "    print('==>')\n",
    "    print('Average of base mIoU: {:.4f}\\tAverage of novel mIoU: {:.4f} \\t(over {} runs)'.format(\n",
    "        base_mIoU.mean(), novel_mIoU.mean(), args.n_runs))\n",
    "    print('Mean --- {:.4f}'.format(agg_mIoU), flush=True)\n",
    "    print('Average runtime / run --- {:.1f}\\n'.format(runtimes.mean()))\n",
    "\n",
    "    resume_random_state(random_state)\n",
    "    return agg_mIoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2d2f8-b495-4df3-b20d-e24a944a9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(parse_args())\n",
    "    args = parse_args()\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(str(x) for x in args.gpus)\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "    if args.debug:\n",
    "        args.test_num = 64\n",
    "        args.n_runs = 2\n",
    "\n",
    "    world_size = len(args.gpus)\n",
    "    distributed = world_size > 1\n",
    "    assert not distributed, 'Testing should not be done in a distributed way'\n",
    "    args.distributed = distributed\n",
    "    args.port = find_free_port()\n",
    "    try:\n",
    "        mp.set_start_method('spawn')\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    mp.spawn(main_worker,\n",
    "             args=(world_size, args),\n",
    "             nprocs=world_size,\n",
    "             join=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62bd6e1f-b79f-4b49-877c-8887ec5ea9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/bin/python: Error while finding module specification for 'src.test' (ModuleNotFoundError: No module named 'src')\n",
      "/home/zeus/miniconda3/envs/cloudspace/bin/python: Error while finding module specification for 'src.test' (ModuleNotFoundError: No module named 'src')\n",
      "/home/zeus/miniconda3/envs/cloudspace/bin/python: Error while finding module specification for 'src.test' (ModuleNotFoundError: No module named 'src')\n",
      "/home/zeus/miniconda3/envs/cloudspace/bin/python: Error while finding module specification for 'src.test' (ModuleNotFoundError: No module named 'src')\n"
     ]
    }
   ],
   "source": [
    "!bash ../test.sh coco20i 5 upperbound [0] out.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f50abdef-5bd1-425e-863e-12e5467f573e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/DIaM/DIaM/src'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5dee953-48ea-49a3-9011-a2610478d6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/DIaM/DIaM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f120dc-4abb-45ed-8b2a-202352b79d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapt_iter: 100\n",
      "batch_size_val: 50\n",
      "bins: [1, 2, 3, 6]\n",
      "bottleneck_dim: 512\n",
      "ckpt_path: model_ckpt/\n",
      "ckpt_used: model\n",
      "cls_lr: 0.00125\n",
      "data_name: coco\n",
      "data_root: data/coco/\n",
      "debug: False\n",
      "dropout: 0.1\n",
      "fine_tune_base_classifier: True\n",
      "generate_new_support_set_for_each_task: False\n",
      "gpus: [0]\n",
      "image_size: 417\n",
      "layers: 50\n",
      "load_model_id: 1\n",
      "m_scale: False\n",
      "manual_seed: 2023\n",
      "mean: [0.485, 0.456, 0.406]\n",
      "n_runs: 5\n",
      "pi_estimation_strategy: upperbound\n",
      "pi_update_at: [10]\n",
      "pin_memory: True\n",
      "pretrained: True\n",
      "shot: 5\n",
      "shuffle_test_data: True\n",
      "split: 0\n",
      "std: [0.229, 0.224, 0.225]\n",
      "support_only_one_novel: True\n",
      "test_num: 10000\n",
      "train_list: lists/coco/train.txt\n",
      "use_split_coco: True\n",
      "use_training_images_for_supports: False\n",
      "val_list: lists/coco/val.txt\n",
      "weights: [100, 1, 1, 100]\n",
      "workers: 3\n",
      "==> Running evaluation script\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/test.py\", line 183, in <module>\n",
      "    mp.spawn(main_worker,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 241, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 197, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
      "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "\n",
      "-- Process 0 terminated with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
      "    fn(i, *args)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/test.py\", line 29, in main_worker\n",
      "    setup(args, rank, world_size)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/util.py\", line 41, in setup\n",
      "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1184, in init_process_group\n",
      "    default_pg, _ = _new_process_group_helper(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1339, in _new_process_group_helper\n",
      "    backend_class = ProcessGroupNCCL(\n",
      "ValueError: ProcessGroupNCCL is only supported with GPUs, no GPUs found!\n",
      "\n",
      "adapt_iter: 100\n",
      "batch_size_val: 50\n",
      "bins: [1, 2, 3, 6]\n",
      "bottleneck_dim: 512\n",
      "ckpt_path: model_ckpt/\n",
      "ckpt_used: model\n",
      "cls_lr: 0.00125\n",
      "data_name: coco\n",
      "data_root: data/coco/\n",
      "debug: False\n",
      "dropout: 0.1\n",
      "fine_tune_base_classifier: True\n",
      "generate_new_support_set_for_each_task: False\n",
      "gpus: [0]\n",
      "image_size: 417\n",
      "layers: 50\n",
      "load_model_id: 1\n",
      "m_scale: False\n",
      "manual_seed: 2023\n",
      "mean: [0.485, 0.456, 0.406]\n",
      "n_runs: 5\n",
      "pi_estimation_strategy: upperbound\n",
      "pi_update_at: [10]\n",
      "pin_memory: True\n",
      "pretrained: True\n",
      "shot: 5\n",
      "shuffle_test_data: True\n",
      "split: 1\n",
      "std: [0.229, 0.224, 0.225]\n",
      "support_only_one_novel: True\n",
      "test_num: 10000\n",
      "train_list: lists/coco/train.txt\n",
      "use_split_coco: True\n",
      "use_training_images_for_supports: False\n",
      "val_list: lists/coco/val.txt\n",
      "weights: [100, 1, 1, 100]\n",
      "workers: 3\n",
      "==> Running evaluation script\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/test.py\", line 183, in <module>\n",
      "    mp.spawn(main_worker,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 241, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 197, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
      "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "\n",
      "-- Process 0 terminated with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
      "    fn(i, *args)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/test.py\", line 29, in main_worker\n",
      "    setup(args, rank, world_size)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/util.py\", line 41, in setup\n",
      "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1184, in init_process_group\n",
      "    default_pg, _ = _new_process_group_helper(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1339, in _new_process_group_helper\n",
      "    backend_class = ProcessGroupNCCL(\n",
      "ValueError: ProcessGroupNCCL is only supported with GPUs, no GPUs found!\n",
      "\n",
      "adapt_iter: 100\n",
      "batch_size_val: 50\n",
      "bins: [1, 2, 3, 6]\n",
      "bottleneck_dim: 512\n",
      "ckpt_path: model_ckpt/\n",
      "ckpt_used: model\n",
      "cls_lr: 0.00125\n",
      "data_name: coco\n",
      "data_root: data/coco/\n",
      "debug: False\n",
      "dropout: 0.1\n",
      "fine_tune_base_classifier: True\n",
      "generate_new_support_set_for_each_task: False\n",
      "gpus: [0]\n",
      "image_size: 417\n",
      "layers: 50\n",
      "load_model_id: 1\n",
      "m_scale: False\n",
      "manual_seed: 2023\n",
      "mean: [0.485, 0.456, 0.406]\n",
      "n_runs: 5\n",
      "pi_estimation_strategy: upperbound\n",
      "pi_update_at: [10]\n",
      "pin_memory: True\n",
      "pretrained: True\n",
      "shot: 5\n",
      "shuffle_test_data: True\n",
      "split: 2\n",
      "std: [0.229, 0.224, 0.225]\n",
      "support_only_one_novel: True\n",
      "test_num: 10000\n",
      "train_list: lists/coco/train.txt\n",
      "use_split_coco: True\n",
      "use_training_images_for_supports: False\n",
      "val_list: lists/coco/val.txt\n",
      "weights: [100, 1, 1, 100]\n",
      "workers: 3\n",
      "==> Running evaluation script\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/test.py\", line 183, in <module>\n",
      "    mp.spawn(main_worker,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 241, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 197, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
      "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "\n",
      "-- Process 0 terminated with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
      "    fn(i, *args)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/test.py\", line 29, in main_worker\n",
      "    setup(args, rank, world_size)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/util.py\", line 41, in setup\n",
      "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1184, in init_process_group\n",
      "    default_pg, _ = _new_process_group_helper(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1339, in _new_process_group_helper\n",
      "    backend_class = ProcessGroupNCCL(\n",
      "ValueError: ProcessGroupNCCL is only supported with GPUs, no GPUs found!\n",
      "\n",
      "adapt_iter: 100\n",
      "batch_size_val: 50\n",
      "bins: [1, 2, 3, 6]\n",
      "bottleneck_dim: 512\n",
      "ckpt_path: model_ckpt/\n",
      "ckpt_used: model\n",
      "cls_lr: 0.00125\n",
      "data_name: coco\n",
      "data_root: data/coco/\n",
      "debug: False\n",
      "dropout: 0.1\n",
      "fine_tune_base_classifier: True\n",
      "generate_new_support_set_for_each_task: False\n",
      "gpus: [0]\n",
      "image_size: 417\n",
      "layers: 50\n",
      "load_model_id: 1\n",
      "m_scale: False\n",
      "manual_seed: 2023\n",
      "mean: [0.485, 0.456, 0.406]\n",
      "n_runs: 5\n",
      "pi_estimation_strategy: upperbound\n",
      "pi_update_at: [10]\n",
      "pin_memory: True\n",
      "pretrained: True\n",
      "shot: 5\n",
      "shuffle_test_data: True\n",
      "split: 3\n",
      "std: [0.229, 0.224, 0.225]\n",
      "support_only_one_novel: True\n",
      "test_num: 10000\n",
      "train_list: lists/coco/train.txt\n",
      "use_split_coco: True\n",
      "use_training_images_for_supports: False\n",
      "val_list: lists/coco/val.txt\n",
      "weights: [100, 1, 1, 100]\n",
      "workers: 3\n",
      "==> Running evaluation script\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/test.py\", line 183, in <module>\n",
      "    mp.spawn(main_worker,\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 241, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 197, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
      "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "\n",
      "-- Process 0 terminated with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
      "    fn(i, *args)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/test.py\", line 29, in main_worker\n",
      "    setup(args, rank, world_size)\n",
      "  File \"/teamspace/studios/this_studio/DIaM/DIaM/src/util.py\", line 41, in setup\n",
      "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n",
      "    func_return = func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1184, in init_process_group\n",
      "    default_pg, _ = _new_process_group_helper(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1339, in _new_process_group_helper\n",
      "    backend_class = ProcessGroupNCCL(\n",
      "ValueError: ProcessGroupNCCL is only supported with GPUs, no GPUs found!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash test.sh coco20i 5 upperbound [0] out.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409d12eb-3377-420d-ac56-ba41c2880eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\tconfig\t   lists       models.zip\t src\t   util\n",
      "README.md\tdata\t   model       out.log\t\t test.sh\n",
      "cocdownload.py\tinitmodel  model_ckpt  requirements.txt  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767edacb-b263-4c6e-966c-c2f42aafcf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
